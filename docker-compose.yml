version: '3.8'

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: rag-chat-backend
    restart: unless-stopped
    environment:
      # LLM Provider (anthropic, openai, azure, ollama)
      - LLM_PROVIDER=${LLM_PROVIDER:-anthropic}

      # Anthropic
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-3-haiku-20240307}

      # OpenAI
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}

      # Azure OpenAI
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY:-}
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT:-}
      - AZURE_OPENAI_DEPLOYMENT=${AZURE_OPENAI_DEPLOYMENT:-}
      - AZURE_API_VERSION=${AZURE_API_VERSION:-2024-02-15-preview}

      # Ollama
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3}

      # Vector DB (chroma, mongodb)
      - VECTOR_DB_PROVIDER=${VECTOR_DB_PROVIDER:-chroma}
      - MONGODB_URI=${MONGODB_URI:-}
      - MONGODB_DB_NAME=${MONGODB_DB_NAME:-rag_chat}
      - MONGODB_COLLECTION=${MONGODB_COLLECTION:-documents}

      # Search
      - ENABLE_HYBRID_SEARCH=${ENABLE_HYBRID_SEARCH:-false}

      # Embeddings
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-BAAI/bge-small-en-v1.5}
    volumes:
      - backend_chroma_db:/app/chroma_db
      - ./backend/sample_data:/app/sample_data:ro
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/api/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: rag-chat-frontend
    restart: unless-stopped
    ports:
      - "80:80"
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:80/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s

volumes:
  backend_chroma_db:
    name: rag-chat-chroma-db
